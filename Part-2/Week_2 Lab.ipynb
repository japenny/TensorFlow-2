{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Coding tutorials\n",
    " #### [1. Keras datasets](#coding_tutorial_1)\n",
    " #### [2. Dataset generators](#coding_tutorial_2)\n",
    " #### [3. Keras image data augmentation](#coding_tutorial_3)\n",
    " #### [4. The Dataset class](#coding_tutorial_4)\n",
    " #### [5. Training with Datasets](#coding_tutorial_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_1\"></a>\n",
    "## Keras datasets\n",
    "\n",
    "For a list of Keras datasets and documentation on recommended usage, see [this link](https://keras.io/datasets/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the CIFAR-100 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the CIFAR-100 dataset\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that reloading the dataset does not require a download\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the shape of the data.\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine one of the images and its corresponding label\n",
    "\n",
    "plt.imshow(train_x[500])\n",
    "print(train_y[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of labels from a JSON file\n",
    "\n",
    "import json\n",
    "\n",
    "with open('data/cifar100_fine_labels.json', 'r') as fine_labels:\n",
    "    cifar100_fine_labels = json.load(fine_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of labels for the CIFAR-100 dataset are available [here](https://www.cs.toronto.edu/~kriz/cifar.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a few of the labels\n",
    "\n",
    "cifar100_fine_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the corresponding label for the example above\n",
    "\n",
    "cifar100_fine_labels[41]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data using different label modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a few examples from category 87 (index 86) and the list of labels\n",
    "\n",
    "examples = train_x[(train_y.T == 86)[0]][:3]\n",
    "fig, ax = plt.subplots(1,3)\n",
    "ax[0].imshow(examples[0])\n",
    "ax[1].imshow(examples[1])\n",
    "ax[2].imshow(examples[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the data using the 'coarse' label mode\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = cifar100.load_data(label_mode='coarse')\n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display three images from the dataset with the label 6 (index 5)\n",
    "\n",
    "examples = train_x[(train_y.T == 5)[0]][:3]\n",
    "fig, ax = plt.subplots(1,3)\n",
    "ax[0].imshow(examples[0])\n",
    "ax[1].imshow(examples[1])\n",
    "ax[2].imshow(examples[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of coarse labels from a JSON file\n",
    "\n",
    "with open('data/cifar100_coarse_labels.json', 'r') as coarse_labels:\n",
    "    cifar100_coarse_labels = json.load(coarse_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print a few of the labels\n",
    "\n",
    "cifar100_coarse_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the corresponding label for the example above\n",
    "\n",
    "print(cifar100_fine_labels[86])\n",
    "print(cifar100_coarse_labels[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the IMDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDB dataset\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print an example from the training dataset, along with its corresponding label\n",
    "\n",
    "print(f'label: {train_y[100]}')\n",
    "print(train_x[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lengths of the input sequences\n",
    "\n",
    "sequence_lengths = [len(seq) for seq in train_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the maximum and minimum sequence length\n",
    "print(max(sequence_lengths))\n",
    "print(min(sequence_lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Keyword Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data ignoring the 50 most frequent words, use oov_char=2 (this is the default)\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = imdb.load_data(skip_top=50, oov_char=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lengths of the input sequences\n",
    "\n",
    "sequence_lengths = [len(seq) for seq in train_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the maximum and minimum sequence length\n",
    "\n",
    "print(max(sequence_lengths))\n",
    "print(min(sequence_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for filtering the sequences\n",
    "\n",
    "def remove_oov_char(element):\n",
    "    ''' Filter function for removing the oov_char. '''\n",
    "    return [word for word in element if word!=2]\n",
    "\n",
    "def filter_list(lst):\n",
    "    ''' Run remove_oov_char on elements in a list. '''\n",
    "    return [remove_oov_char(element) for element in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the oov_char from the sequences using the filter_list function\n",
    "\n",
    "train_x = filter_list(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lengths of the input sequences\n",
    "\n",
    "sequence_lengths = [len(seq) for seq in train_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the maximum and minimum sequence length\n",
    "\n",
    "print(max(sequence_lengths))\n",
    "print(min(sequence_lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_2\"></a>\n",
    "## Dataset generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the UCI Fertility Dataset\n",
    "\n",
    "We will be using a dataset available at https://archive.ics.uci.edu/ml/datasets/Fertility from UC Irvine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fertility dataset\n",
    "\n",
    "headers = ['Season', 'Age', 'Diseases', 'Trauma', 'Surgery', 'Fever', 'Alcohol', 'Smoking', 'Sitting', 'Output']\n",
    "fertility = pd.read_csv('data/fertility_diagnosis.txt', delimiter=',', header=None, names=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the DataFrame\n",
    "\n",
    "fertility.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the head of the DataFrame\n",
    "\n",
    "fertility.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the 'Output' feature from 'N' to 0 and from 'O' to 1\n",
    "\n",
    "fertility['Output'] = fertility['Output'].map(lambda x : 0.0 if x=='N' else 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the head of the DataFrame\n",
    "\n",
    "fertility.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame so that the features are mapped to floats\n",
    "\n",
    "fertility = fertility.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the DataFrame\n",
    "\n",
    "fertility = fertility.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show the head of the DataFrame\n",
    "\n",
    "fertility.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the field Season to a one-hot encoded vector\n",
    "\n",
    "fertility = pd.get_dummies(fertility, prefix='Season', columns=['Season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the head of the DataFrame\n",
    "\n",
    "fertility.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*N.B. The below cell has been updated since the coding tutorial.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the Output column such that it is the last column in the DataFrame\n",
    "\n",
    "fertility = fertility.reindex(columns = [col for col in fertility.columns if col != 'Output'] + ['Output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the head of the DataFrame\n",
    "\n",
    "fertility.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame to a numpy array.\n",
    "\n",
    "fertility = fertility.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation set\n",
    "\n",
    "training = fertility[:70]\n",
    "validation = fertility[70:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the shape of the training data\n",
    "\n",
    "print(training.shape)\n",
    "print(validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features and labels for the validation and training data\n",
    "\n",
    "training_features = training[:,0:-1]\n",
    "training_labels = training[:,-1]\n",
    "validation_features = validation[:,0:-1]\n",
    "validation_labels = validation[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that returns a generator producing inputs and labels\n",
    "\n",
    "def get_generator(features, labels, batch_size=1):\n",
    "    for n in range(int(len(features)/batch_size)):\n",
    "        yield (features[n*batch_size: (n+1)*batch_size], labels[n*batch_size: (n+1)*batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to our training features and labels with a batch size of 10\n",
    "\n",
    "train_generator = get_generator(training_features, training_labels, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the generator using the next() function\n",
    "\n",
    "print(next(train_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model using Keras with 3 layers\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization\n",
    "\n",
    "input_shape = (12,)\n",
    "output_shape = (1,)\n",
    "\n",
    "model_input = Input(input_shape)\n",
    "batch_1 = BatchNormalization(momentum=0.8)(model_input)\n",
    "dense_1 = Dense(100, activation='relu')(batch_1)\n",
    "batch_2 = BatchNormalization(momentum=0.8)(dense_1)\n",
    "output = Dense(1, activation='sigmoid')(batch_2)\n",
    "\n",
    "model = Model([model_input], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the model summary to show the resultant structure\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the optimizer object\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with loss function and metric\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and evaluate the model using the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of training steps per epoch for the given batch size.\n",
    "\n",
    "batch_size = 5\n",
    "train_steps = len(training) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the epochs to 3\n",
    "\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_gen = get_generator(training_features, training_labels, batch_size=batch_size)\n",
    "    val_gen = get_generator(validation_features, validation_labels, batch_size=len(validation_labels))\n",
    "\n",
    "    model.fit_generator(train_gen, \n",
    "                        validation_data=val_gen, validation_steps=1, \n",
    "                        steps_per_epoch=train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to run the fit_generator function once more; observe what happens\n",
    "\n",
    "model.fit_generator(train_gen, steps_per_epoch=train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make an infinitely looping generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that returns an infinitely looping generator\n",
    "\n",
    "def get_generator_cyclic(features, labels, batch_size=1):\n",
    "    while True:\n",
    "        for n in range(int(len(features)/batch_size)):\n",
    "            yield (features[n*batch_size: (n+1)*batch_size], labels[n*batch_size: (n+1)*batch_size])\n",
    "            \n",
    "        permuted = np.random.permutation(len(features))\n",
    "        features = features[permuted]\n",
    "        labels = labels[permuted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a generator using this function.\n",
    "\n",
    "train_gen_cyc = get_generator_cyclic(training_features, training_labels, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert that the new cyclic generator does not raise a StopIteration\n",
    "\n",
    "for i in range(2*train_steps):\n",
    "    next(train_gen_cyc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a cyclic validation generator\n",
    "\n",
    "val_gen_cyc = get_generator_cyclic(validation_features, validation_labels, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "model.fit_generator(train_gen_cyc, \n",
    "                    validation_data=val_gen_cyc, validation_steps=1, \n",
    "                    steps_per_epoch=train_steps, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model and get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's obtain a validation data generator.\n",
    "\n",
    "validation_generator = get_generator(validation_features, validation_labels, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on the validation data\n",
    "\n",
    "preds = model.predict_generator(validation_generator, steps=1)\n",
    "print(np.round(preds.T[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the corresponding validation labels\n",
    "\n",
    "print(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a validation data generator\n",
    "\n",
    "validation_generator = get_generator(validation_features, validation_labels, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_3\"></a>\n",
    "## Keras image data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "\n",
    "(training_features, training_labels), (test_features, test_labels) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels to a one-hot encoding\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "training_labels = tf.keras.utils.to_categorical(training_labels, num_classes)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that returns a data generator\n",
    "\n",
    "def get_generator(features, labels, batch_size=1):\n",
    "    for n in range(int(len(features)/batch_size)):\n",
    "        yield (features[n*batch_size:(n+1)*batch_size], labels[n*batch_size:(n+1)*batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function we created to get a training data generator with a batch size of 1\n",
    "\n",
    "training_generator = get_generator(training_features, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess the shape of the items generated by training_generator using the `next` function to yield an item.\n",
    "\n",
    "image, label = next(training_generator)\n",
    "print(image.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the training generator by obtaining an image using the `next` generator function, and then using imshow to plot it.\n",
    "# Print the corresponding label\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "image, label = next(training_generator)\n",
    "image_unbatched = image[0,:,:,:]\n",
    "imshow(image_unbatched)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the generator by re-running the `get_generator` function.\n",
    "\n",
    "train_generator = get_generator(training_features, training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a data augmention generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to convert an image to monochrome\n",
    "\n",
    "def monochrome(x):\n",
    "    def func_bw(a):\n",
    "        average_colour = np.mean(a)\n",
    "        return [average_colour, average_colour, average_colour]\n",
    "    x = np.apply_along_axis(func_bw, -1, x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ImageDataGenerator object\n",
    "\n",
    "image_gen = ImageDataGenerator(\n",
    "                preprocessing_function=monochrome,\n",
    "                rotation_range=180,\n",
    "                rescale=(1/255.0))\n",
    "\n",
    "image_gen.fit(training_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check [the documentation](https://keras.io/preprocessing/image/) for the full list of image data augmentation options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an iterable generator using the `flow` function\n",
    "\n",
    "image_gen_iter = image_gen.flow(training_features, training_labels,\n",
    "                                batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show a sample from the generator and compare with the original\n",
    "\n",
    "image, label = next(image_gen_iter)\n",
    "image_orig, label_orig = next(train_generator)\n",
    "figs, axes = plt.subplots(1,2)\n",
    "axes[0].imshow(image_orig[0,:,:,:])\n",
    "axes[0].set_title('Original')\n",
    "axes[1].imshow(image[0,:,:,:])\n",
    "axes[1].set_title('Transformed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flow from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the directory structure\n",
    "\n",
    "train_path = 'data/flowers-recognition-split/train'\n",
    "val_path = 'data/flowers-recognition-split/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ImageDataGenerator object\n",
    "\n",
    "datagenerator = ImageDataGenerator(rescale=(1/255.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training data generator\n",
    "\n",
    "train_gen = datagenerator.flow_from_directory(train_path,\n",
    "                                              batch_size=64, classes=classes,\n",
    "                                              target_size=(16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a validation data generator\n",
    "\n",
    "val_gen = datagenerator.flow_from_directory(val_path,\n",
    "                                            batch_size=64, classes=classes,\n",
    "                                            target_size=(16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and display an image and label from the training generator\n",
    "\n",
    "x = next(train_gen)\n",
    "imshow(x[0][4])\n",
    "print(x[1][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the training generator\n",
    "\n",
    "train_gen = datagenerator.flow_from_directory(train_path,\n",
    "                                              batch_size=64, \n",
    "                                              classes=classes, target_size=(16,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build a CNN model\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Flatten, Dense\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Input((16,16,3)))\n",
    "model.add(Conv2D(8, (8, 8), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D((4,4)))\n",
    "model.add(Conv2D(8, (8, 8), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(4, (4, 4), padding='same', activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an optimizer object\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the training generator and test generator steps per epoch\n",
    "\n",
    "train_steps_per_epoch = train_gen.n // train_gen.batch_size\n",
    "val_steps = val_gen.n // val_gen.batch_size\n",
    "print(train_steps_per_epoch, val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "\n",
    "model.fit_generator(train_gen, \n",
    "                    steps_per_epoch=train_steps_per_epoch, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "model.evaluate_generator(val_gen,\n",
    "                         steps=val_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict using the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels with the model\n",
    "\n",
    "preds = model.predict(val_gen, steps=1)\n",
    "np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_4\"></a>\n",
    "## The Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a simple dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((100,10,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset from the tensor x\n",
    "\n",
    "ds1 = tf.data.Dataset.from_tensor_slices(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the Dataset object\n",
    "\n",
    "print(ds1)\n",
    "print(ds1.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = [np.zeros((10,2,2)), np.zeros((5,2,2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try creating a dataset from the tensor x2\n",
    "\n",
    "ds2 = tf.data.Dataset.from_tensor_slices(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = [np.zeros((10,1)), np.zeros((10,1)), np.zeros((10,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another dataset from the new x2 and inspect the Dataset object\n",
    "\n",
    "ds2 = tf.data.Dataset.from_tensor_slices(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the element_spec\n",
    "\n",
    "print(ds2.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a zipped dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two datasets into one larger dataset\n",
    "\n",
    "ds_zip = tf.data.Dataset.zip((ds1, ds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the element_spec\n",
    "\n",
    "print(ds_zip.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to find the number of batches in a dataset\n",
    "\n",
    "def get_batches(dataset):\n",
    "    iter_dataset = iter(dataset)\n",
    "    i = 0\n",
    "    try:\n",
    "        while next(iter_dataset):\n",
    "            i = i+1\n",
    "    except:\n",
    "        return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of batches in the zipped Dataset\n",
    "\n",
    "get_batches(ds_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataset from numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "\n",
    "(train_features, train_labels), (test_features, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print(type(train_features), type(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataset from the MNIST data\n",
    "\n",
    "mnist_dataset = tf.data.Dataset.from_tensor_slices((train_features, train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the Dataset object\n",
    "\n",
    "print(mnist_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the length of an element using the take method\n",
    "\n",
    "ele = next(iter(mnist_dataset.take(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the shapes of the data\n",
    "\n",
    "print(ele[0].shape)\n",
    "print(ele[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataset from text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the list of text files\n",
    "\n",
    "text_files = sorted([f.path for f in os.scandir('data/shakespeare')])\n",
    "\n",
    "print(text_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first file using python and print the first 5 lines.\n",
    "\n",
    "with open(text_files[0], 'r') as fil:\n",
    "    contents = [fil.readline() for i in range(5)]\n",
    "    for line in contents:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the lines from the files into a dataset using TextLineDataset\n",
    "\n",
    "shakespeare_dataset = tf.data.TextLineDataset(text_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the take method to get and print the first 5 lines of the dataset\n",
    "\n",
    "first_5_lines_dataset = iter(shakespeare_dataset.take(5))\n",
    "lines = [line for line in first_5_lines_dataset]\n",
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of lines in the first file\n",
    "\n",
    "lines = []\n",
    "with open(text_files[0], 'r') as fil:\n",
    "    line = fil.readline()\n",
    "    while line:\n",
    "        lines.append(line)\n",
    "        line = fil.readline()\n",
    "    print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of lines in the shakespeare dataset we created\n",
    "\n",
    "shakespeare_dataset_iterator = iter(shakespeare_dataset)\n",
    "lines = [line for line in shakespeare_dataset_iterator]\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interleave lines from the text data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a dataset of the text file strings\n",
    "\n",
    "text_files_dataset = tf.data.Dataset.from_tensor_slices(text_files)\n",
    "files = [file for file in text_files_dataset]\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interleave the lines from the text files\n",
    "\n",
    "interleave_sp_ds = text_files_dataset.interleave(tf.data.TextLineDataset, cycle_length=9)\n",
    "print(interleave_sp_ds.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 10 elements of the interleaved dataset\n",
    "\n",
    "lines = [line for line in iter(interleave_sp_ds.take(10))]\n",
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_5\"></a>\n",
    "## Training with Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the UCI Bank Marketing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a pandas DataFrame\n",
    "\n",
    "bank_dataframe = pd.read_csv('data/bank/bank-full.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the head of the DataFrame\n",
    "\n",
    "bank_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45211, 17)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the DataFrame\n",
    "\n",
    "print(bank_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features from the DataFrame\n",
    "\n",
    "features = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
    "            'loan', 'contact', 'campaign', 'pdays', 'poutcome']\n",
    "labels = ['y']\n",
    "\n",
    "bank_dataframe = bank_dataframe.filter(features + labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  campaign  pdays poutcome   y  \n",
       "0  unknown         1     -1  unknown  no  \n",
       "1  unknown         1     -1  unknown  no  \n",
       "2  unknown         1     -1  unknown  no  \n",
       "3  unknown         1     -1  unknown  no  \n",
       "4  unknown         1     -1  unknown  no  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the head of the DataFrame\n",
    "\n",
    "bank_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the categorical features in the DataFrame to one-hot encodings\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "categorical_features = ['default', 'housing', 'job', 'loan', 'education', 'contact', 'poutcome']\n",
    "\n",
    "for feature in categorical_features:\n",
    "    bank_dataframe[feature] = tuple(encoder.fit_transform(bank_dataframe[feature]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>(0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>married</td>\n",
       "      <td>(0, 0, 1, 0)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>2143</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>(0, 0, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0)</td>\n",
       "      <td>single</td>\n",
       "      <td>(0, 1, 0, 0)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>29</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>(0, 0, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>(0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>married</td>\n",
       "      <td>(0, 1, 0, 0)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>2</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>(0, 0, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>(0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>married</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>1506</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>(0, 0, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1)</td>\n",
       "      <td>single</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>1</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>(0, 0, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age                                   job  marital     education default  \\\n",
       "0   58  (0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)  married  (0, 0, 1, 0)    (0,)   \n",
       "1   44  (0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0)   single  (0, 1, 0, 0)    (0,)   \n",
       "2   33  (0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0)  married  (0, 1, 0, 0)    (0,)   \n",
       "3   47  (0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)  married  (0, 0, 0, 1)    (0,)   \n",
       "4   33  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1)   single  (0, 0, 0, 1)    (0,)   \n",
       "\n",
       "   balance housing  loan    contact  campaign  pdays      poutcome   y  \n",
       "0     2143    (1,)  (0,)  (0, 0, 1)         1     -1  (0, 0, 0, 1)  no  \n",
       "1       29    (1,)  (0,)  (0, 0, 1)         1     -1  (0, 0, 0, 1)  no  \n",
       "2        2    (1,)  (1,)  (0, 0, 1)         1     -1  (0, 0, 0, 1)  no  \n",
       "3     1506    (1,)  (0,)  (0, 0, 1)         1     -1  (0, 0, 0, 1)  no  \n",
       "4        1    (0,)  (0,)  (0, 0, 1)         1     -1  (0, 0, 0, 1)  no  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the head of the DataFrame\n",
    "\n",
    "bank_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*N.B. The below cell has been updated to correct the name of a variable and differs from the Coding Tutorial video.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the DataFrame\n",
    "\n",
    "bank_dataframe = bank_dataframe.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Dataset object\n",
    "\n",
    "*N.B. Please use ``bank_dataframe.to_dict(orient='list')`` to convert the correct dataframe to a dictionary suitable for use in the ``from_tensor_slices`` function, rather than ``dict(dataframe)`` as specified in the coding tutorial video.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame to a Dataset\n",
    "\n",
    "bank_ds = tf.data.Dataset.from_tensor_slices(bank_dataframe.to_dict(orient='list'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'job': TensorSpec(shape=(12,), dtype=tf.int32, name=None),\n",
       " 'marital': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       " 'education': TensorSpec(shape=(4,), dtype=tf.int32, name=None),\n",
       " 'default': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'balance': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'housing': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'loan': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'contact': TensorSpec(shape=(3,), dtype=tf.int32, name=None),\n",
       " 'campaign': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'pdays': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'poutcome': TensorSpec(shape=(4,), dtype=tf.int32, name=None),\n",
       " 'y': TensorSpec(shape=(), dtype=tf.string, name=None)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the Dataset object\n",
    "\n",
    "bank_ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a person with marital status: b'married'\n"
     ]
    }
   ],
   "source": [
    "# First check that there are records in the dataset for non-married individuals\n",
    "\n",
    "def check_divorced():\n",
    "    bank_dataset_iterable = iter(bank_ds)\n",
    "    for x in bank_dataset_iterable:\n",
    "        if x['marital'] != 'divorced':\n",
    "            print('Found a person with marital status: {}'.format(x['marital']))\n",
    "            return\n",
    "    print('No non-divorced people were found!')\n",
    "\n",
    "check_divorced()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the Dataset to retain only entries with a 'divorced' marital status\n",
    "\n",
    "bank_ds = bank_ds.filter(lambda x : tf.equal(x['marital'], tf.constant([b'divorced']))[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No non-divorced people were found!\n"
     ]
    }
   ],
   "source": [
    "# Check the records in the dataset again\n",
    "\n",
    "check_divorced()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map a function over the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the label ('y') to an integer instead of 'yes' or 'no'\n",
    "\n",
    "def map_label(x):\n",
    "    x['y'] = 0 if (x['y'] == tf.constant([b'no'], dtype=tf.string)) else 1\n",
    "    return x\n",
    "\n",
    "bank_ds = bank_ds.map(map_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'job': TensorSpec(shape=(12,), dtype=tf.int32, name=None),\n",
       " 'marital': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       " 'education': TensorSpec(shape=(4,), dtype=tf.int32, name=None),\n",
       " 'default': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'balance': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'housing': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'loan': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'contact': TensorSpec(shape=(3,), dtype=tf.int32, name=None),\n",
       " 'campaign': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'pdays': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'poutcome': TensorSpec(shape=(4,), dtype=tf.int32, name=None),\n",
       " 'y': TensorSpec(shape=(), dtype=tf.int32, name=None)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the Dataset object\n",
    "\n",
    "bank_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'marital' column\n",
    "\n",
    "bank_ds = bank_ds.map(lambda x: {key:val for key,val in x.items() if key != 'marital'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'job': TensorSpec(shape=(12,), dtype=tf.int32, name=None),\n",
       " 'education': TensorSpec(shape=(4,), dtype=tf.int32, name=None),\n",
       " 'default': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'balance': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'housing': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'loan': TensorSpec(shape=(1,), dtype=tf.int32, name=None),\n",
       " 'contact': TensorSpec(shape=(3,), dtype=tf.int32, name=None),\n",
       " 'campaign': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'pdays': TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
       " 'poutcome': TensorSpec(shape=(4,), dtype=tf.int32, name=None),\n",
       " 'y': TensorSpec(shape=(), dtype=tf.int32, name=None)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the Dataset object\n",
    "\n",
    "bank_ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create input and output data tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input and output tuple for the dataset\n",
    "\n",
    "def map_feature_label(x):\n",
    "    features = [[x['age']], [x['balance']], [x['campaign']], x['contact'], x['default'],\n",
    "                x['education'], x['housing'], x['job'], x['loan'], [x['pdays']], x['poutcome']]\n",
    "    return (tf.concat(features, axis=0), x['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Map this function over the dataset\n",
    "\n",
    "bank_ds = bank_ds.map(map_feature_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(30,), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the Dataset object\n",
    "\n",
    "bank_ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into a training and a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5207\n"
     ]
    }
   ],
   "source": [
    "# Determine the length of the Dataset\n",
    "\n",
    "dataset_length = 0\n",
    "\n",
    "for _ in bank_ds:\n",
    "    dataset_length += 1\n",
    "    \n",
    "print(dataset_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and validation sets from the dataset\n",
    "\n",
    "training_ele = int(dataset_length * 0.7)\n",
    "train_ds = bank_ds.take(training_ele)\n",
    "val_ds = bank_ds.skip(training_ele)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a classification model\n",
    "\n",
    "Now let's build a model to classify the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a classifier model\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, BatchNormalization\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(30,)))\n",
    "model.add(BatchNormalization(momentum=0.8))\n",
    "model.add(Dense(400, activation='relu'))\n",
    "model.add(BatchNormalization(momentum=0.8))\n",
    "model.add(Dense(400, activation='relu'))\n",
    "model.add(BatchNormalization(momentum=0.8))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 400)               12400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 400)               1600      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 400)               1600      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 401       \n",
      "=================================================================\n",
      "Total params: 176,521\n",
      "Trainable params: 174,861\n",
      "Non-trainable params: 1,660\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show the model summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batched training and validation datasets\n",
    "\n",
    "train_dataset = train_ds.batch(20, drop_remainder=True)\n",
    "valid_dataset = val_ds.batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the training data\n",
    "\n",
    "train_dataset = train_dataset.shuffle(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<TakeDataset shapes: ((30,), ()), types: (tf.int32, tf.int32)>,\n",
       " (TensorSpec(shape=(30,), dtype=tf.int32, name=None),\n",
       "  TensorSpec(shape=(), dtype=tf.int32, name=None)))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds, train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "182/182 [==============================] - 21s 118ms/step - loss: 0.6620 - accuracy: 0.6467 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "182/182 [==============================] - 21s 114ms/step - loss: 0.4801 - accuracy: 0.8234 - val_loss: 0.5010 - val_accuracy: 0.8362\n",
      "Epoch 3/5\n",
      "182/182 [==============================] - 21s 116ms/step - loss: 0.3757 - accuracy: 0.8915 - val_loss: 0.4047 - val_accuracy: 0.8663\n",
      "Epoch 4/5\n",
      "182/182 [==============================] - 19s 105ms/step - loss: 0.3034 - accuracy: 0.9190 - val_loss: 0.4201 - val_accuracy: 0.8612\n",
      "Epoch 5/5\n",
      "182/182 [==============================] - 18s 100ms/step - loss: 0.2558 - accuracy: 0.9283 - val_loss: 0.4117 - val_accuracy: 0.8612\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=valid_dataset,\n",
    "                    epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "plt.plot(history.epoch, history.history['accuracy'], label='training')\n",
    "plt.plot(history.epoch, history.history['val_accuracy'], label='validation')\n",
    "plt.title('Epoch vs Accuracy')\n",
    "plt.legend()\n",
    "plt.ylabel('Epoch')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
